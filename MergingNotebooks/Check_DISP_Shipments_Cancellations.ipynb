{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#!python --version  #Python 3.8.2\n",
    "#pd.__version__     #1.0.3 \n",
    "#re.__version__     #2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM SETTINGS set these as appropriate for your environment\n",
    "\n",
    "# Enter the path to the local data files:\n",
    "path_datafiles = \"OriginalData/\"\n",
    "\n",
    "# Download the state names/abbreviations from US Postal Service Publication 28\n",
    "#              https://pe.usps.com/text/pub28/28apb.htm\n",
    "#        Required to verify that state abbreviations are valid.\n",
    "#        Expects first column is state name, second column is state abbreviation.\n",
    "# Enter the path to the file on your system.\n",
    "postal_file = '20200712_StateAbbreviations.txt'\n",
    "\n",
    "# Get quarterly LESO Shipment and Cancellation data file from \n",
    "#     Defense Logicstics Agency Law Enforcement Support Office Public Information\n",
    "# Orginal name of the data file should be in the form:\n",
    "#      DISP_Shipments_Cancellations_mmddyyyy_mmddyyyy.xlsx  \n",
    "# Enter the local file name\n",
    "LESO_file = \"DISP_Shipments_Cancellations_04012020_06302020.xlsx\"\n",
    "#LESO_file = \"DISP_Shipments_Cancellations_01012020_03312020.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISP_Shipments_Cancellations_mmddyyyy_mmddyyyy.xlsx is downloaded from:    \n",
    "https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/   \n",
    "The following is an image of the relevant section of the website:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](Images/DISP_Shipments_CancellationsXLSX.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check DISP_Shipments_Cancellations_mmddyyyy_mmddyyyy.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook checks that the schema matches previous versions of the file. It checks for null/NaN data, some unique values, and that 'State' is a valid two-letter abbreviation. It expects that the XLSX file has two sheets labeled 'SHIPMENTS' and 'CANCELLATIONS' The two sheets have the different columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Expected Columns in 'SHIPMENTS' sheet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__State__: two digit postal abbreviation<br>\n",
    "> TYPE:str LENGTH: 2 CHARACTER_SET: [A-Z]   \n",
    "\n",
    "__Station Name (LEA)__: descriptive name of agency requesting equipment<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies   \n",
    "\n",
    "__Requisition ID__: ???unique??? alphanumeric string<br>\n",
    "> TYPE:str LENGTH: 14 CHARACTER_SET: [A-z0-9]   \n",
    "\n",
    "__FSC__: Federal Supply Classification Group number<br>\n",
    "part of NATO Stock Number, see https://en.wikipedia.org/wiki/NATO_Stock_Number<br>\n",
    "> TYPE:str LENGTH:4 CHARACTER_SET: [0-9] varies (xx: FSG yy: FSC)   \n",
    "\n",
    "__NIIN__: National Item Identification number<br>\n",
    "part of NATO Stock Number, see https://en.wikipedia.org/wiki/NATO_Stock_Number<br>\n",
    "> TYPE:str LENGTH:9 CHARACTER_SET: varies {xx:CC||NCB yyy-yyyy: non-standard item code}   \n",
    "\n",
    "__Item Name__: descriptive item name<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies   \n",
    "\n",
    "__UI__: unit increment<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies   \n",
    "\n",
    "__Quantity__: number of items requested<br>\n",
    "> TYPE:int LENGTH: varies CHARACTER_SET: [0-9]   \n",
    "\n",
    "__Acquisition Value__: value of requested items in dollars<br>\n",
    "> TYPE:float64 LENGTH: varies CHARACTER_SET: [0-9.]   \n",
    "\n",
    "__Date Shipped__: ???date shipped???<br>\n",
    "> TYPE:datetime64 LENGTH:29 CHARACTER_SET: yyyy-mm-ddT00:00:00.000000000   \n",
    "\n",
    "__Justification__: descriptive text<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Expected Columns in 'CANCELLATIONS' sheet:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Cancelled By__: ???cancelling agency???<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies   \n",
    "\n",
    "__RTD Ref__: ???unique??? reference number<br>\n",
    "> TYPE:int LENGTH: 6 or 7 CHARACTER_SET: [0-9]  \n",
    "\n",
    "__State__: two digit postal abbreviation<br>\n",
    "> TYPE:str LENGTH: 2 CHARACTER_SET: [A-Z]   \n",
    "\n",
    "__Station Name (LEA)__: descriptive name of agency requesting equipment<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies   \n",
    "\n",
    "__FSC__: Federal Supply Classification Group number<br>\n",
    "part of NATO Stock Number, see https://en.wikipedia.org/wiki/NATO_Stock_Number<br>\n",
    "> TYPE:str LENGTH:4 CHARACTER_SET: [0-9] {aabb: FSG(aa),FSC(bb)}   \n",
    "\n",
    "__NIIN__: National Item Identification number<br>\n",
    "part of NATO Stock Number, see https://en.wikipedia.org/wiki/NATO_Stock_Number<br>\n",
    "> TYPE:str LENGTH:9 CHARACTER_SET: [A-Z0-9] {aabbbbbbb: CC||NCB(aa),non-standard item code(bbbbbbb)}   \n",
    "\n",
    "__Item Name__: descriptive item name<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies   \n",
    "\n",
    "__UI__: unit increment<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies   \n",
    "\n",
    "__Quantity__: number of items requested<br>\n",
    "> TYPE:int LENGTH: varies CHARACTER_SET: [0-9]   \n",
    "\n",
    "__Acquisition Value__: value of requested items in dollars<br>\n",
    "> TYPE:float64 LENGTH: varies CHARACTER_SET: [0-9.]   \n",
    "\n",
    "__Date Requested__: ???date requested???<br>\n",
    "> TYPE:datetime64 LENGTH:29 CHARACTER_SET: yyyy-mm-ddThh:mm:ss.000000000   \n",
    "\n",
    "__Justification__: descriptive text<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies   \n",
    "\n",
    "__Reason Cancelled__: ???descriptive reason for cancellation???<br>\n",
    "> TYPE:str LENGTH: varies CHARACTER_SET: varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data From xlsx File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_cancel_df = pd.read_excel(\"file:\" + path_datafiles + LESO_file, sheet_name=None)\n",
    "#transfer_df is a dictionary of two sheets in filename\n",
    "#keys are 'SHIPMENTS', 'CANCELLATIONS'\n",
    "#values are a single dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on sheets from previous files\n",
    "expected_sheets = ['SHIPMENTS','CANCELLATIONS']\n",
    "\n",
    "# based on columns from previous files\n",
    "expected_shipments_columns = ['State', 'Station Name (LEA)', 'Requisition ID', \n",
    "                              'FSC', 'NIIN', 'Item Name', 'UI', 'Quantity', \n",
    "                              'Acquisition Value', 'Date Shipped', 'Justification']\n",
    "expected_cancellations_columns = ['Cancelled By', 'RTD Ref', 'State', 'Station Name (LEA)', \n",
    "                                  'FSC', 'NIIN', 'Item Name', 'UI', 'Quantity', \n",
    "                                  'Acquisition Value', 'Date Requested', 'Justification', \n",
    "                                  'Reason Cancelled']\n",
    "\n",
    "# dictionary based on U.S. Postal data from 'fullpath_postalfile'\n",
    "#     key: state abbreviation, value: state name\n",
    "expected_state_abbreviations = pd.read_csv(path_datafiles + postal_file,header=None,\n",
    "                                           quotechar = \"'\").\\\n",
    "                                           set_index([1])[0].to_dict() \n",
    "#len(expected_state_abbreviations) #expect 59 U.S. states and territories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions for Checking the Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(df: pd.DataFrame,col: str) -> list:\n",
    "    '''Returns a list of the unique values in a column given a dictionary of dataframes.    \n",
    "    \n",
    "    '''\n",
    "    unique_values_list = []\n",
    "    for dict_key in df:\n",
    "        unique_values_array = df[dict_key][col].unique()\n",
    "        for val in df[dict_key][col].unique():\n",
    "            unique_values_list.append(val)\n",
    "    return unique_values_list\n",
    "\n",
    "def get_unexpected_values(to_check: set,expect: set)-> set:\n",
    "    '''Returns a set of unexpected values, empty if none found.\n",
    "    \n",
    "    '''\n",
    "    return to_check.difference(expect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for 2 Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(ship_cancel_df) #dict\n",
    "#len(ship_cancel_df.values()) #2\n",
    "#for val in ship_cancel_df.values():\n",
    "#    print('\\n',type(val)) #<class 'pandas.core.frame.DataFrame'>\n",
    "unexpected_sheets = get_unexpected_values(set(ship_cancel_df.keys()),\n",
    "                                          set(expected_sheets))\n",
    "if (len(ship_cancel_df.keys()) != 2) | (len(unexpected_sheets) != 0):\n",
    "    print('XLSX has unexpected sheets:',ship_cancel_df.keys())\n",
    "else:\n",
    "    shipments_df = ship_cancel_df[expected_sheets[0]]\n",
    "    cancellations_df = ship_cancel_df[expected_sheets[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shipments_df has shape:',shipments_df.shape)\n",
    "print('cancellations_df has shape:',cancellations_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shipments_df has these default data types:',shipments_df.dtypes)\n",
    "print('cancellations_df has these default data types:',cancellations_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Shipments dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Do the 'State' abbreviations in the 'SHIPMENTS' dataframe match US postal abbreviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_state_abbr = [state_abbr for state_abbr in shipments_df['State'] \n",
    "                         if state_abbr not in expected_state_abbreviations]\n",
    "if len(incorrect_state_abbr) > 0:\n",
    "    print('These states have inconsistant state/territory abbreviations:',incorrect_state_abbr)\n",
    "else:\n",
    "    print('No inconsistant state abbreviations were found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What columns are in the 'SHIPMENTS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = get_unexpected_values(set(shipments_df.columns), set(expected_shipments_columns))\n",
    "missing_columns = get_unexpected_values(set(expected_shipments_columns),set(shipments_df.columns))\n",
    "\n",
    "print('Expected columns are:',expected_shipments_columns)\n",
    "if len(new_columns) > 0:\n",
    "    print('These unexpected columns found:\\n',new_columns)\n",
    "elif len(missing_columns) > 0:\n",
    "    print('These columns are missing:\\n',missing_columns)\n",
    "else:\n",
    "    print('\\nNo column discrepancies found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many unique values are in each column of the 'SHIPMENTS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipments_df.groupby('State').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many null/NaN values are in the 'SHIPMENTS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipments_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What can we learn about the 'Requistion ID' values in the 'SHIPMENTS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length,Count:')\n",
    "print(dict(shipments_df['Requisition ID'].str.len().value_counts()))\n",
    "print('Number of unique values:',shipments_df['Requisition ID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Cancellations dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Do the 'State' abbreviations in the 'CANCELLATIONS' dataframe match US postal abbreviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_state_abbr = [state_abbr for state_abbr in cancellations_df['State'] \n",
    "                         if state_abbr not in expected_state_abbreviations]\n",
    "if len(incorrect_state_abbr) > 0:\n",
    "    print('These states have inconsistant state/territory abbreviations:',incorrect_state_abbr)\n",
    "else:\n",
    "    print('No inconsistant state abbreviations were found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What columns are in the 'CANCELLATIONS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = get_unexpected_values(set(cancellations_df.columns), set(expected_cancellations_columns))\n",
    "missing_columns = get_unexpected_values(set(expected_cancellations_columns),set(cancellations_df.columns))\n",
    "\n",
    "print('Expected columns are:',expected_cancellations_columns)\n",
    "if len(new_columns) > 0:\n",
    "    print('These unexpected columns found:\\n',new_columns)\n",
    "elif len(missing_columns) > 0:\n",
    "    print('These columns are missing:\\n',missing_columns)\n",
    "else:\n",
    "    print('\\nNo column discrepancies found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many unique values are in each column of the 'CANCELLATIONS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellations_df.groupby('State').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What unique values are found in the 'Cancelled By' column of the 'CANCELLATION dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellations_df['Cancelled By'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many null/NaN values are in the 'CANCELLATIONS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellations_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What can we learn about the 'RTD Ref' values in the 'CANCELLATIONS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length,Count:')\n",
    "print(dict(cancellations_df['RTD Ref'].astype(str).str.len().value_counts()))\n",
    "print('Number of unique values:',cancellations_df['RTD Ref'].nunique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
