{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# !python --version    #Python 3.8.5\n",
    "# pd.__version__       #1.1.2\n",
    "# re.__version__       #2.2.1\n",
    "#  datetime standard module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions\n",
    "def make_dataframe(a_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\" Return dataframe of all values in dictionary.\"\"\"\n",
    "    a_df = pd.concat([pd.concat([v],ignore_index=True) for k,v in a_dict.items()],ignore_index=True).\\\n",
    "                    apply(lambda x: x.str.strip() if x.dtype == 'object' else x)\n",
    "    a_df.index = a_df['Ship Date']\n",
    "    a_df.index = a_df.index.normalize()\n",
    "    a_df.index.name = 'Date'\n",
    "    return a_df\n",
    "\n",
    "\n",
    "def count_by_time(frame1: pd.DataFrame, frame2: pd.DataFrame,\n",
    "                  start: str, end: str, time_unit: str) -> pd.DataFrame:\n",
    "    \"\"\" return a single dataframe with only rows where column counts are different \"\"\"\n",
    "    count_frame1 = frame1.loc[start:end].groupby(pd.Grouper(freq=time_unit))['State'].count()\n",
    "    count_frame2 = frame2.loc[start:end].groupby(pd.Grouper(freq=time_unit))['State'].count()\n",
    "    counts_df = pd.DataFrame({'count1': count_frame1, 'count2': count_frame2}, index=count_frame2.index)\n",
    "    return counts_df[(counts_df['count1'] != counts_df['count2'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the path to the local copy of original data files:\n",
    "path_datafiles = \"../../data/\"\n",
    "\n",
    "# Get quarterly cumulative LESO Transferred Property data file from \n",
    "#     Defense Logicstics Agency Law Enforcement Support Office Public Information\n",
    "# Orginal name of the data file should be in the form:\n",
    "#      DISP_AllStatesAndTerritories_mmddyyyy.xlsx  \n",
    "# Enter the local file name\n",
    "LESO_Q1_file = \"DISP_AllStatesAndTerritories_03312020.xlsx\"\n",
    "LESO_Q2_file = \"DISP_AllStatesAndTerritories_06302020.xlsx\"\n",
    "#LESO_Q3_file = \"DISP_AllStatesAndTerritories_009302020.xlsx\"\n",
    "#LESO_Q4_file = \"DISP_AllStatesAndTerritories_12312020.xlsx\"\n",
    "start_date = '2017-01-01'\n",
    "end_date = '2020-03-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into dictionary of states (sheet names) and dataframes (sheet contents)\n",
    "q1_dict = pd.read_excel(\"file:\" + path_datafiles + LESO_Q1_file, sheet_name=None)\n",
    "q2_dict = pd.read_excel(\"file:\" + path_datafiles + LESO_Q2_file, sheet_name=None)\n",
    "#q3_dict = pd.read_excel(\"file:\" + path_datafiles + LESO_Q3_file, sheet_name=None)\n",
    "#q4_dict = pd.read_excel(\"file:\" + path_datafiles + LESO_Q4_file, sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes from dictionaries for two quarters being compared\n",
    "start_df = make_dataframe(q1_dict)\n",
    "end_df = make_dataframe(q2_dict)\n",
    "print('Shape of starting quarter:', start_df.loc[start_date:end_date].shape)\n",
    "print('Shape of ending quarter:', end_df.loc[start_date:end_date].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What years have discrepancies?\n",
    "count_by_time(start_df, end_df, start_date, end_date, 'Y')\n",
    "#ax = count_by_time(start_df, end_df, start_date, end_date, 'Y').plot.bar(rot=90,figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What months have discrepancies in a given year?\n",
    "year_start = '2019-01-01'\n",
    "year_end = '2019-12-31'\n",
    "count_by_time(start_df, end_df, year_start, year_end, 'M')\n",
    "#ax = count_by_time(start_df, end_df, year_start, year_end, 'M').plot.bar(rot=90,figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### First month with discrepancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What weeks have discrepancies in a month of a year?\n",
    "month_start = '2019-05-01'\n",
    "month_end = '2019-05-31'\n",
    "count_by_time(start_df, end_df, month_start, month_end, 'W')\n",
    "#ax = count_by_time(start_df, end_df, month_start, month_end, 'W').plot.bar(rot=90,figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which days have discrepances in a given week?\n",
    "week_start = '2019-06-16'\n",
    "week_end = '2019-06-23'\n",
    "count_by_time(start_df, end_df, week_start, week_end, 'D')\n",
    "#ax = count_by_time(start_df, end_df, week_start, week_end, 'D').plot.bar(rot=90,figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which day did the discrepancy occur?\n",
    "day_of_interest = '2019-06-21'\n",
    "merged_df = pd.merge(start_df.loc[day_of_interest], end_df.loc[day_of_interest], how='outer', indicator=True)\n",
    "merged_df[merged_df['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the merged data doesn't find the discrepancy, then try the following\n",
    "start_lea_count = start_df.loc[day_of_interest].groupby(['Station Name (LEA)'])['Station Name (LEA)'].count()\n",
    "end_lea_count = end_df.loc[day_of_interest].groupby(['Station Name (LEA)'])['Station Name (LEA)'].count()\n",
    "concat_count = pd.concat([start_lea_count, end_lea_count], axis=1)\n",
    "concat_count.fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if more than on month has discrepancies, repeat previous 4 cells as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
