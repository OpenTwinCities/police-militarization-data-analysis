{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#!python --version  #Python 3.8.5\n",
    "#pd.__version__      #1.1.2 \n",
    "#re.__version__     #2.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM SETTINGS set these as appropriate for your environment\n",
    "\n",
    "# Enter the path to the local data files:\n",
    "path_datafiles = \"../../data/\"\n",
    "\n",
    "# Download the state names/abbreviations from US Postal Service Publication 28\n",
    "#              https://pe.usps.com/text/pub28/28apb.htm\n",
    "#        Required to verify that state abbreviations are valid.\n",
    "#        Expects first column is state name, second column is state abbreviation.\n",
    "# Enter the path to the file on your system.\n",
    "postal_file = '20200712_StateAbbreviations.txt'\n",
    "\n",
    "# Get quarterly LESO Shipment and Cancellation data file from \n",
    "#     Defense Logicstics Agency Law Enforcement Support Office Public Information\n",
    "# Orginal name of the data file should be in the form:\n",
    "#      DISP_Shipments_Cancellations_mmddyyyy_mmddyyyy.xlsx  \n",
    "# Enter the local file name\n",
    "#LESO_file = \"DISP_Shipments_Cancellations_01012020_03312020.xlsx\"\n",
    "#LESO_file = \"DISP_Shipments_Cancellations_04012020_06302020.xlsx\"\n",
    "LESO_file = \"DISP_Shipments_Cancellations_07012020_09302020.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISP_Shipments_Cancellations_mmddyyyy_mmddyyyy.xlsx is downloaded from:    \n",
    "https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/   \n",
    "The following is an image of the relevant section of the website:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](../Images/DISP_Shipments_CancellationsXLSX.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check DISP_Shipments_Cancellations_mmddyyyy_mmddyyyy.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook checks that the schema matches previous versions of the file. It checks for null/NaN data, some unique values, and that 'State' is a valid two-letter abbreviation. It expects that the XLSX file has two sheets labeled 'SHIPMENTS' and 'CANCELLATIONS' The two sheets have the different columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Dictionary for Shipments sheet of Shipments_Cancellations files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "| Field | Data Type | Description | Length | Expected Pattern | null? |   \n",
    "| ----- | ---- | ---- | ---- | ---- |---- |   \n",
    "| State | string | two digit postal abbreviation for U.S. state or territory| 2 | \\[A-Z\\]\\[A-Z\\] | no |   \n",
    "| Station Name (LEA) | string | descriptive name of requesting law enforcement agency | varies | varies | no |   \n",
    "| Requisition ID | string | apparently unique identifier needs further research | 14 | [A-z0-9]{14} | no |   \n",
    "| FSC | string | [Federal Supply Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#Federal_Supply_Classification_Group_(FSCG)) consisting of the Federal Supply Group and Federal Supply Classification | 4 | \\[0-9\\]{4} | no |   \n",
    "| NIIN | string | [National Item Identification Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#National_Item_Identification_Number_(NIIN)) a Country Code followed by a 7-digit item identifier string | 9 | \\[0-9\\]{9} | no |   \n",
    "| Item Name | string | descriptive name of requested item | varies | varies | no |   \n",
    "| UI | string | units of requested item known as unit increments | varies | varies | no |   \n",
    "| Quantity | integer | number of units requested | varies | [0-9]+ | no |   \n",
    "| Acquisition Value | float | U.S. dollar amount paid when the item was originally purchased by the government | varies | [0-9]+.[0-9]{2} | no |   \n",
    "| Date Shipped | datetime64 | date shipped maybe; needs further research | 29 | yyyy-mm-ddT00:00:00.000000000 | no |   \n",
    "| Justification | string | descriptive text justifying request; needs further research | varies | varies | yes |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Dictionary for Cancellations sheet of Shipments_Cancellations files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "| Field | Data Type | Description | Length | Expected Pattern | null? |   \n",
    "| ----- | ---- | ---- | ---- | ---- |---- |   \n",
    "| Cancelled By | string | apparently agency that cancelled request; needs further research | varies | varies | yes | \n",
    "| RTD Ref | string | apparently unique identifier; needs further research | 6 or 7 | [0-9]{7} | no |   \n",
    "| State | string | two digit postal abbreviation for U.S. state or territory| 2 | \\[A-Z\\]\\[A-Z\\] | no |   \n",
    "| Station Name (LEA) | string | descriptive name of requesting law enforcement agency | varies | varies | no |   \n",
    "| FSC | string | [Federal Supply Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#Federal_Supply_Classification_Group_(FSCG)) consisting of the Federal Supply Group and Federal Supply Classification | 4 | \\[0-9\\]{4} | no |   \n",
    "| NIIN | string | [National Item Identification Number](https://en.wikipedia.org/wiki/NATO_Stock_Number#National_Item_Identification_Number_(NIIN)) a Country Code followed by a 7-digit item identifier string | 9 | \\[0-9\\]{9} | no |   \n",
    "| Item Name | string | descriptive name of requested item | varies | varies | no |   \n",
    "| UI | string | units of requested item known as unit increments | varies | varies | no |   \n",
    "| Quantity | integer | number of units requested | varies | [0-9]+ | no |   \n",
    "| Acquisition Value | float | U.S. dollar amount paid when the item was originally purchased by the government | varies | [0-9]+.[0-9]{2} | no |   \n",
    "| Date Requested | datetime64 | date request made; needs further research | 29 | yyyy-mm-ddT00:00:00.000000000 | no |   \n",
    "| Justification | string | descriptive text justifying request; needs further research | varies | varies | yes |   \n",
    "| Reason Cancelled | string | capitalized code followed by description of why request is cancelled; needs further research | varies | varies | yes |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data From xlsx File:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_cancel_df = pd.read_excel(\"file:\" + path_datafiles + LESO_file, sheet_name=None)\n",
    "#transfer_df is a dictionary of two sheets in filename\n",
    "#keys are 'SHIPMENTS', 'CANCELLATIONS'\n",
    "#values are a single dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on sheets from previous files\n",
    "expected_sheets = ['SHIPMENTS','CANCELLATIONS']\n",
    "\n",
    "# based on columns from previous files\n",
    "expected_shipments_columns = ['State', 'Station Name (LEA)', 'Requisition ID', \n",
    "                              'FSC', 'NIIN', 'Item Name', 'UI', 'Quantity', \n",
    "                              'Acquisition Value', 'Date Shipped', 'Justification']\n",
    "expected_cancellations_columns = ['Cancelled By', 'RTD Ref', 'State', 'Station Name (LEA)', \n",
    "                                  'FSC', 'NIIN', 'Item Name', 'UI', 'Quantity', \n",
    "                                  'Acquisition Value', 'Date Requested', 'Justification', \n",
    "                                  'Reason Cancelled']\n",
    "\n",
    "# dictionary based on U.S. Postal data from 'fullpath_postalfile'\n",
    "#     key: state abbreviation, value: state name\n",
    "expected_state_abbreviations = pd.read_csv(path_datafiles + postal_file,header=None,\n",
    "                                           quotechar = \"'\").\\\n",
    "                                           set_index([1])[0].to_dict() \n",
    "#len(expected_state_abbreviations) #expect 59 U.S. states and territories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions for Checking the Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(df: pd.DataFrame,col: str) -> list:\n",
    "    '''Returns a list of the unique values in a column given a dictionary of dataframes.    \n",
    "    \n",
    "    '''\n",
    "    unique_values_list = []\n",
    "    for dict_key in df:\n",
    "        unique_values_list += list(df[dict_key][col].unique())\n",
    "    return unique_values_list\n",
    "\n",
    "def get_unexpected_values(to_check: set,expect: set)-> set:\n",
    "    '''Returns a set of unexpected values, empty if none found.\n",
    "    \n",
    "    '''\n",
    "    return to_check.difference(expect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for 2 Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(ship_cancel_df) #dict\n",
    "#len(ship_cancel_df.values()) #2\n",
    "#for val in ship_cancel_df.values():\n",
    "#    print('\\n',type(val)) #<class 'pandas.core.frame.DataFrame'>\n",
    "unexpected_sheets = get_unexpected_values(set(ship_cancel_df.keys()),\n",
    "                                          set(expected_sheets))\n",
    "if (len(ship_cancel_df.keys()) != 2) | (len(unexpected_sheets) != 0):\n",
    "    print('XLSX has unexpected sheets:',ship_cancel_df.keys())\n",
    "else:\n",
    "    shipments_df = ship_cancel_df[expected_sheets[0]]\n",
    "    cancellations_df = ship_cancel_df[expected_sheets[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shipments_df has shape:',shipments_df.shape)\n",
    "print('cancellations_df has shape:',cancellations_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('shipments_df has these default data types:',shipments_df.dtypes)\n",
    "print('cancellations_df has these default data types:',cancellations_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Shipments dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Do the 'State' abbreviations in the 'SHIPMENTS' dataframe match US postal abbreviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_state_abbr = [state_abbr for state_abbr in shipments_df['State'] \n",
    "                         if state_abbr not in expected_state_abbreviations]\n",
    "if len(incorrect_state_abbr) > 0:\n",
    "    print('These states have inconsistant state/territory abbreviations:',incorrect_state_abbr)\n",
    "else:\n",
    "    print('No inconsistant state abbreviations were found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What columns are in the 'SHIPMENTS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = get_unexpected_values(set(shipments_df.columns), set(expected_shipments_columns))\n",
    "missing_columns = get_unexpected_values(set(expected_shipments_columns),set(shipments_df.columns))\n",
    "\n",
    "print('Expected columns are:',expected_shipments_columns)\n",
    "if len(new_columns) > 0:\n",
    "    print('These unexpected columns found:\\n',new_columns)\n",
    "elif len(missing_columns) > 0:\n",
    "    print('These columns are missing:\\n',missing_columns)\n",
    "else:\n",
    "    print('\\nNo column discrepancies found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many unique values are in each column of the 'SHIPMENTS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipments_df.groupby('State').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many null/NaN values are in the 'SHIPMENTS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipments_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What can we learn about the 'Requistion ID' values in the 'SHIPMENTS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length,Count:')\n",
    "print(dict(shipments_df['Requisition ID'].str.len().value_counts()))\n",
    "print('Number of unique values:',shipments_df['Requisition ID'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the Cancellations dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Do the 'State' abbreviations in the 'CANCELLATIONS' dataframe match US postal abbreviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_state_abbr = [state_abbr for state_abbr in cancellations_df['State'] \n",
    "                         if state_abbr not in expected_state_abbreviations]\n",
    "if len(incorrect_state_abbr) > 0:\n",
    "    print('These states have inconsistant state/territory abbreviations:',incorrect_state_abbr)\n",
    "else:\n",
    "    print('No inconsistant state abbreviations were found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What columns are in the 'CANCELLATIONS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = get_unexpected_values(set(cancellations_df.columns), set(expected_cancellations_columns))\n",
    "missing_columns = get_unexpected_values(set(expected_cancellations_columns),set(cancellations_df.columns))\n",
    "\n",
    "print('Expected columns are:',expected_cancellations_columns)\n",
    "if len(new_columns) > 0:\n",
    "    print('These unexpected columns found:\\n',new_columns)\n",
    "elif len(missing_columns) > 0:\n",
    "    print('These columns are missing:\\n',missing_columns)\n",
    "else:\n",
    "    print('\\nNo column discrepancies found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many unique values are in each column of the 'CANCELLATIONS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellations_df.groupby('State').nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What unique values are found in the 'Cancelled By' column of the 'CANCELLATION dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellations_df['Cancelled By'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many null/NaN values are in the 'CANCELLATIONS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellations_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: What can we learn about the 'RTD Ref' values in the 'CANCELLATIONS' dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length,Count:')\n",
    "print(dict(cancellations_df['RTD Ref'].astype(str).str.len().value_counts()))\n",
    "print('Number of unique values:',cancellations_df['RTD Ref'].nunique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
