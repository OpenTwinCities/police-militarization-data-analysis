{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from math import nan\n",
    "\n",
    "#!python --version  #Python 3.8.5\n",
    "#pd.__version__     #1.1.2 \n",
    "#re.__version__     #2.2.1\n",
    "# math is a standard library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUSTOM SETTINGS: set these as appropriate for your environment\n",
    "\n",
    "# Enter the path to the local data files:\n",
    "path_datafiles = \"../../data/\"\n",
    "\n",
    "# Download the state names/abbreviations from US Postal Service Publication 28\n",
    "#              https://pe.usps.com/text/pub28/28apb.htm\n",
    "#        Required to verify that state abbreviations are valid.\n",
    "#        Expects first column is state name, second column is state abbreviation.\n",
    "# Enter the path to the file on your system.\n",
    "postal_file = '20200712_StateAbbreviations.txt'\n",
    "\n",
    "# Get quarterly cumulative LESO Transferred Property data file from \n",
    "#     Defense Logicstics Agency Law Enforcement Support Office Public Information\n",
    "# Orginal name of the data file should be in the form:\n",
    "#      DISP_AllStatesAndTerritories_mmddyyyy.xlsx  \n",
    "# Enter the local file name\n",
    "\n",
    "#LESO_file = \"DISP_AllStatesAndTerritories_03312020.xlsx\"\n",
    "#LESO_file = \"DISP_AllStatesAndTerritories_06302020.xlsx\"\n",
    "LESO_file = \"DISP_AllStatesAndTerritories_09302020.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISP_AllStatesAndTerritories_mmddyyyy.xlsx is downloaded from:   \n",
    "https://www.dla.mil/DispositionServices/Offers/Reutilization/LawEnforcement/PublicInformation/   \n",
    "The following is an image of the relevant section of the website:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](../Images/DISP_AllStatesAndTerritoriesXLXS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check DISP_AllStatesAndTerritories_mmddyyyy.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook checks that the schema matches previous versions of the file. It checks for null/NaN data, some unique values, and that 'State' is a valid two-letter abbreviation. It expects that the XLSX file has up to 59 sheets labeled by full state or territory name. Each sheet should have the same columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Dictionary for AllStatesAndTerritories files:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "| Field | Data Type | Description | Length | Expected Pattern | null? |   \n",
    "| ----- | ---- | ---- | ---- | ---- |---- |   \n",
    "| State | string | two digit postal abbreviation for U.S. state or territory | 2 | \\[A-Z\\]\\[A-Z\\] | no |   \n",
    "| Station Name (LEA) | string | descriptive name of requesting law enforcement agency | varies | varies | no |   \n",
    "| NSN | string | [NATO Stock Number](https://en.wikipedia.org/wiki/NATO_Stock_Number) a government-assigned identifier for requested item | 9 | \\[0-9\\]{4}-\\[0-9\\]{2}-\\[A-Z0-9\\]{3}-\\[A-Z0-9\\]{4} | no |   \n",
    "| Item Name | string | descriptive name of requested item | varies | varies | no |   \n",
    "| UI | string | units of requested item known as unit increments | varies | varies | no |   \n",
    "| Quantity | integer | number of units requested | varies | [0-9]+ | no |   \n",
    "| Acquisition Value | float | U.S. dollar amount paid when the item was originally purchased by the government | varies | [0-9]+.[0-9]{2} | no |   \n",
    "| DEMIL Code | character | [demilitarization code](https://www.dla.mil/HQ/LogisticsOperations/Services/FIC/DEMILCoding/DEMILCodes/) for level of destruction required when the item leaves Department of Defense control | 1 | \\[GPFDCEBQA\\] | no |   \n",
    "| DEMIL IC | integer | [demilitarization itegrity code](https://www.dla.mil/HQ/LogisticsOperations/Services/FIC/DEMILCoding/DEMILCodes/) validity of DEMIL Code (a missing value means it has not yet been reviewed), see [FLIS manual](https://www.dla.mil/HQ/LogisticsOperations/TrainingandReference/FLISProcedures/) for more information | 1 | [0-9] or blank | yes |   \n",
    "| Ship Date | datetime64 | date transfered; needs further research | 29 | yyyy-mm-ddT00:00:00.000000000 | no |   \n",
    "| Station Type | string | level of government associated with requesting agency; needs further research | 5 | 'State' | no |   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data From xlsx File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_dict = pd.read_excel(\"file:\" + path_datafiles + LESO_file, sheet_name=None)\n",
    "#transfer_dict is a dictionary of all sheets in filename\n",
    "#keys are full state/territory names\n",
    "#values are a single dataframe of all transfers for that state/territory, cumulative to this quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on columns in sheets from previous files\n",
    "expected_columns = ['Complete State','State', 'Station Name (LEA)',\n",
    "                    'NSN', 'Item Name', 'Quantity', 'UI', 'Acquisition Value',\n",
    "                    'DEMIL Code', 'DEMIL IC', 'Ship Date','Station Type']\n",
    "\n",
    "# based on previous values\n",
    "expected_station_types = ['State']\n",
    "\n",
    "# based on DOD 4160.28 DEMIL Program or DOD 4100.39M FLIS Manual and this website:\n",
    "# https://www.dla.mil/HQ/LogisticsOperations/Services/FIC/DEMILCoding/DEMILCodes/\n",
    "expected_demil_codes = ['G','P','F','D','C','E','B','Q','A']\n",
    "# based on DOD 4160.28 DEMIL Program or DOD 4100.39M FLIS Manual and this website:\n",
    "# https://www.dla.mil/HQ/LogisticsOperations/Services/FIC/DEMILCoding/DEMILCodes/\n",
    "expected_demil_integritycodes = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "# dictionary based on U.S. Postal data from 'fullpath_postalfile'\n",
    "#     key: state abbreviation, value: state name\n",
    "expected_state_abbreviations = pd.read_csv(path_datafiles + postal_file,header=None,\n",
    "                                           quotechar = \"'\").\\\n",
    "                                           set_index([1])[0].to_dict() \n",
    "#len(expected_state_abbreviations) #expect 59 U.S. states and territories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions for Checking the Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(df: pd.DataFrame,col: str) -> list:\n",
    "    '''Returns a list of the unique values in a column given a dictionary of dataframes.    \n",
    "    \n",
    "    '''\n",
    "    unique_values_list = []\n",
    "    for dict_key in df:\n",
    "        unique_values_list += list(df[dict_key][col].unique())\n",
    "    return unique_values_list\n",
    "#NOTE from Nicole B\n",
    "# and from mymodule import get_unique_values instead of repeating in each notebook.\n",
    "def get_unexpected_values(to_check: set,expect: set)-> set:\n",
    "    '''Returns a set of unexpected values, empty if none found.\n",
    "    \n",
    "    '''\n",
    "    return to_check.difference(expect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check All Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('transfer_dict has',len(transfer_dict),'sheets')\n",
    "print('transfer_dict has',sum([len(x) for x in transfer_dict.values()]),'rows in all sheets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Do the state or territory names on all sheets match U.S. postal names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_state_names = [state_name for state_name in transfer_dict \n",
    "                         if state_name not in expected_state_abbreviations.values()]\n",
    "for i in incorrect_state_names:\n",
    "    print('Misspelled state/territory name: ',i,' abbreviated as ',transfer_dict[i]['State'].unique(),\n",
    "          ' Correct state name: ',expected_state_abbreviations[transfer_dict[i]['State'].unique()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Does each sheet have exactly one value for 'State'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistant_state_abbreviations = [state_name for state_name in transfer_dict\n",
    "                                    if len(transfer_dict[state_name]['State'].unique()) != 1]\n",
    "if len(inconsistant_state_abbreviations) > 0:\n",
    "    print('These states do not have exactly one state/territory abbreviation:',inconsistant_state_abbreviations)\n",
    "else:\n",
    "    print('All sheets have exactly one state/territory abbreviation.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Are the values of 'State' valid U.S. postal abbreviations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexpected_state_abbreviations = get_unexpected_values(set(get_unique_values(transfer_dict,'State')),\n",
    "                                               set(expected_state_abbreviations.keys()))\n",
    "\n",
    "#print('Expected state abbreviations:',list(expected_state_abbreviations.keys()))\n",
    "if len(unexpected_state_abbreviations) == 0:\n",
    "    print('\\nOnly valid state abbreviations found.')\n",
    "else:\n",
    "    print('\\nThese state abbreviations are not valid:',list(unexpected_state_abbreviations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Do all sheets have the expected columns? (each dictionary item is a data frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_discrepancy = []\n",
    "for state_name in transfer_dict:\n",
    "    if expected_columns is list(transfer_dict[state_name]):\n",
    "        column_discrepancy.append(state_name)\n",
    "\n",
    "print('Expected columns are:',expected_columns)\n",
    "if len(column_discrepancy) > 0:\n",
    "    print('Columns need to be checked on these states:\\n',column_discrepancy)\n",
    "else:\n",
    "    print('\\nNo column discrepancies found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many unique values are in each column of each sheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = pd.DataFrame(columns=expected_columns)\n",
    "count = 0\n",
    "for state_name in transfer_dict:\n",
    "    for k,v in transfer_dict[state_name].nunique().iteritems():\n",
    "        #print(k,v)\n",
    "        unique_counts.loc[count, k] = v\n",
    "    unique_counts.loc[count,'Complete State'] = state_name\n",
    "    count+=1\n",
    "unique_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: How many null/NaN values are in each column of each sheet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = pd.DataFrame(columns=expected_columns)\n",
    "count = 0\n",
    "for state_name in transfer_dict:\n",
    "    for k,v in transfer_dict[state_name].isna().sum().iteritems():\n",
    "    #for k,v in transfer_df[state_name].isnull().sum().iteritems():\n",
    "        #print(k,v)\n",
    "        null_counts.loc[count, k] = v\n",
    "    null_counts.loc[count,'Complete State'] = state_name\n",
    "    count+=1\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Are the unique values of 'Station Type' as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexpected_station_types = get_unexpected_values(set(get_unique_values(transfer_dict,'Station Type')),\n",
    "                                                 set(expected_station_types))\n",
    "\n",
    "#print('Expected station types:',expected_station_types)\n",
    "if len(unexpected_station_types) == 0:\n",
    "    print('\\nOnly expected station types found.')\n",
    "else:\n",
    "    print('\\nFound these unexpected station types:',list(unexpected_station_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Are the unique values of 'DEMIL Code' as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexpected_demil_codes = get_unexpected_values(set(get_unique_values(transfer_dict,'DEMIL Code')),\n",
    "                                               set(expected_demil_codes))\n",
    "\n",
    "#print('Expected DEMIL codes:',expected_demil_codes)\n",
    "if len(unexpected_demil_codes) == 0:\n",
    "    print('\\nOnly expected DEMIL codes found.')\n",
    "else:\n",
    "    print('\\nFound these unexpected DEMIL codes:',list(unexpected_demil_codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### QUESTION: Are the unique values of 'DEMIL IC' as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexpected_demil_integritycodes = get_unexpected_values(set(get_unique_values(transfer_dict,'DEMIL IC')),\n",
    "                                                        set(expected_demil_integritycodes))\n",
    "\n",
    "#print('Expected DEMIL integrity codes:',expected_demil_integritycodes,'\\n')\n",
    "non_nan_list = []\n",
    "[non_nan_list.append(ic) for ic in unexpected_demil_integritycodes if pd.notna(ic)]\n",
    "if len(non_nan_list) > 0:\n",
    "    print('Found these unexpected DEMIL integrity codes:',non_nan_list)\n",
    "else:\n",
    "    print('Only expected integrity codes found.')\n",
    "print('Found',len(unexpected_demil_integritycodes) - len(non_nan_list),\n",
    "      'sheets with NaN DEMIL integrity codes values. Recall that means the items have yet to be coded by DLA.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
